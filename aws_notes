AWS: S3 - Simple Storage Service.

ref: https://aws.amazon.com/es/documentation/s3/

INTRODUCTION:
============

you can put any data file in S3
they are organiced in "Buckets".
-Bucket names are globally unique, so you have to take one with a name non taken yet.

easy to DNS CNAME a URL to your bucket.
bucket name: sergio-images
but my desired domein is sergio.collado.com 

so: sergio.collado.com -> collado-images.s3.amazonaws.com

and include in the web, as:

<html>
<body>
<img src="http://sergio.collado/path/to/logo" alt="AWS_lOGO">
...

ACCESS CONTROL:
==============

Objects, also have 4 types of access control:
 · IAM policies
 · Bucket policies
 · ACLs(Acess Control Lists) - AWS console
 · Query string autentification - gives expiring acess.
 
 
 more info about Buckets in: http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucketPolicies.html
 more info about ACLs in: http://docs.aws.amazon.com/AmazonS3/latest/dev/S3_ACLs_UsingACLs.html
 
 The bucket also saves some information about the files: type, creation date, ...
 more info in: http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html
 
STORING POLICIES:
=================

There are three ways to store policies:
 · Standard ( "11 9's") - that means that if you have 1 million files stored there, you will loose one, everty 10.000 years.
   · it comes at greatest cost, but is the default.
 · Reduced Redundancy Storage (RRS) - is ("4 9s") - it means that if you have 10000 files there, you'll probable loose one every year.
   · It cost is reduced about 20% / Great for reproducible assets
   · RRS, can trigger notifications, on "object missing". 
 · Glaciar it has ("11 9's), but is great draw back is queued retrieval -you cannot get it back in real time- 
   · But is cost is about the 10% of the standard option - which make a great choise for arcivals, and back-ups.
   
PRICING:
========

Starts around 0.10$ per GB/month for "standard" S3 - the fee gets cheaper, if you use more.

Bandwith:
  IN: FREE
  OUT: Same Region: free
       Out of region: Starts at 0.12$ GB/month.
  REQUEST al also costy: (PUT, GET, POST, LIST) - Starts at 0.0055/1000 request.
   
 Just have in mind, that data trasnsfer inside your region is free!  
   
   
ADVANCED FEATURES OF S3
=======================

 S3 also allows for:
 
  ·light, static, website hosting.
  ·Object squeduled expiration.
  ·Encryption Options
  ·Versioning
  ·Logging
  ·"Direct from browser" upload to s3
  ·Multipart files upload
  ·Requested pays
  ·BitTorrent Support
   
- Simple static website hosting: You can rename to a domain you own  (Easy CNAMEd).
- Index, and Error documents support.
- key prefix routing rules.
- Oject expiration squeduling -live cicle management- 
- Encription options (SSE, SSL, or your own) [SSE: Server Side Encription]
- Versioning. Once is On, it can never can go back to Off, so you will be storing all your development. ##
- Logging: you can get IP, operations, dates, . Can be On/Off anytime. Watch out! store the logs, in another Bucket!
- Direct on brownser upload: You can grant users to directly upload to your bucket uses IAM/STS services to generate a url for
the bucket object. 5GB limitation on file size. ref -> http://aws.amazon.com/articles/1434
 If you want to upload more than 5GB, you have to use multi-part files upload, that is just limited to SDK(Java, iOs,PHP, Ruby); 
 the client chuncks the file into pieces. Loads each piece separately. Client closes file. S3 reassembles the file. This also allows
 stop/star partial uploads. With this method the max file size is 5TB.
 ref: http://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html
 - Request payment. always if the client is a AWS registered partner/customer.
 - Bittorret support (P2P protocoll) max file size 5GB
 ref: http://docs.aws.amazon.com/AmazonS3/latest/dev/S3Torrent.html
 
 
 ·First steps: 
 
The best is to migrate all static content to S3 (images, CSS, Javascript, HTML, etc...)- this reliebes the load on your
EBS, so it can do more important tasks, with this, the cost of the EBS, is much more lower, and gets more performance.
   
The second step, is set up Glacier for archival, Control access, set up Livecicle policies, Investigate advanced users: 
like Website hosting, direct to S3 uploads.
 
