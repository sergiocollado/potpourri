DETERMINISTIC SYSTEMS:
=====================
a deterministic system is a system in which no randomness is involved in the development of future states of the system. A deterministic
model will thus always produce the same output from a given starting condition or initial state.

What makes algorithms non-deterministic?
========================================

A variety of factors can cause an algorithm to behave in a way which is not deterministic, or non-deterministic:

 - If it uses external state other than the input, such as user input, a global variable, a hardware timer value, a random value,
or stored disk data.
 - If it operates in a way that is timing-sensitive, for example if it has multiple processors writing to the same data at the same time. In this case, the precise order in which each processor writes its data will affect the result.
 - If a hardware error causes its state to change in an unexpected way.
 
Although real programs are rarely purely deterministic, it is easier for humans as well as other programs to reason about programs
that are. For this reason, most programming languages and especially functional programming languages make an effort to prevent
the above events from happening except under controlled conditions.

The prevalence of multi-core processors has resulted in a surge of interest in determinism in parallel programming and challenges
of non-determinism have been well documented.[1][2] A number of tools to help deal with the challenges have been
proposed[3][4][5][6] to deal with deadlocks and race conditions.



Scheduling for real-time systems:
=================================

We want to comply with time constrictions and functionality constrictions.

The schedule orginaize the tastk for try to comply with the above requirements.

So we can find, several task status:

- Ready state: It's not executed at the moment, but it is such a state, that can start exectution, when the sckedule, signals it.
  
- Running state: When the sckquedule tast is Ready, and is selected for execution, it start its action, and now is Running.

- Blocked state: When a Running Task is running, it can be blocked for several reasons. That means that this task is not running any
more, and cannot be squeduled at the next squeduling point. This can happen, when that Task is in a delay, waiting data to be send, or
receiving data. When the delay runs out, then the Task, moves its state to Ready Task, and it can be scheduled again.

¿Can a Task, put another Task in Blocked state? - Yes.

-Suspensiton state: Another state, is the Suspension of a task, if the user or the systme, consider that this task should not be scheduled
again. 


A squedule that never looses a death line is call FEASEABLE, this depends on its schedule algorithm.

Scheduling example:


|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|----->

0     1     2     3     4     5     6     7     8     9     10

And three tasts: T1, T2 and T3:


T - task
T1 -task 1. time(T1) = 1
T2 -task 2. time(T2) = 0.5
T3 -task 3. time(T3) = 3

 ____    __     ________________
|    |  |  |   |                |
| T1 |  |T2|   |      T3        |
|____|  |__|   |________________|


With the deathlines acording to the figure below:


D - death-line
D1 -death-line task1 = 2
D2 -death-line tast2 = 2.5
D3 -death-line tast3 = 5

           D1 D2             D3
            |  |              |
            V  V              V
|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|----->
0     1     2     3     4     5     6     7     8     9     10


The schedule may want to allocate the T3, the first, because it might be the most important one:



           D1 D2             D3
            |  |              |
            V  V              V
|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|----->
0     1     2     3     4     5     6     7     8     9     10
 ________________ ____ __  
|                |    |  |
|      T3        | T1 |T2|  
|________________|____|__|

- but, by doing so, we make the Task1, and Task2, miss their death lines.

This squeduler is not feaseble, even thougth Task3, might be the most important task.

But if we change the squedule, so it choose first T1, and then T2, and then T3, we see:

           D1 D2             D3
            |  |              |
            V  V              V
|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|----->
0     1     2     3     4     5     6     7     8     9     10
 __________________________ 
|    |  |                  |
| T1 |T2|        T3        |          
|____|__|__________________|

 
Then all three task meet their deathlines. :v: </br>

So now our sistema has became feaseble!!  :ok_hand: </br> 

In many sistems, is not just order the possible tast, but you have to take into account the relationship between tasks, because 
ones can be dependant of the results of others tastks.- This states the problem of priority of tasks, - and sometime we found the 
problem of priority inversion :S ... if we are not careful.


PRE-EMPTIVE SYSTESM:

 In a Job is running, and is stoped, for running another job, and then it is call again, and it continues, where it have stoped, then
 this schedule type is known as a pre-emptive system.
 
 So a PRE-EMPTIVE SYSTEM is that one that can stop the current process, perfom another second process, and then again, continue the fist
 process, where it was left.
 
 For a scheduler to be pre-emptive, the scheduler must be able to save the current status of the actual task, and then switch to another
 task.
 
 The process of switching context, usually is triggered by a timer, provided by de OS, when the timer triggers the interrupt, this makes
 the OS, run a routine call, __IRS__(), first thing it does is block the interrupts, so nothing can change its process. Then it stores
 the regitsters, to the task stack -using architecture specific, assembly code- 
 
 Void __ISR__(){
 cli(); //disable interrupts - clear interrupts
 stores_context(); 
 next_job();
 load_context();
 sei(); //enable interrupts - set interrupts
 reti(); //return - return from isr
 }
 
 Then the schedule decides on what will be the next task, and then loads the context back to the new task, because this was saved
 last time the task was interrumped. Now the system is ready to continue executing.the OS enables interrupts again, and then returns
 from the ISR.
 
 This procedure of context switch, takes some time, and is refered as the "Context Switch overhead", and must be taken into account,
 when planning a real-time system and its timeline.
 
TODO: STATIC SCHEDULER:
=======================
 
TODO: FIXED SCHEDULING
======================







 
MONOTONIC SCHEDULING
====================

Monotonic scheduling have the advantge when scheduling periodic jobs, becase they  base the selection of tasks executions, 
on the time to death line or periods. That implies that is easier to systematically plan the system. So monotonic schedulers
are simple jet effective because they can addapt the priorities of the tasks implicity during runtime.

The advantage of monotonic scheduling systems is the system verification. There are verification methods that allows us to say if
a monotonic scheduling is feasible, based on periods, execution time, and tasks deadlines.

two monotonic scheduler will be study:
- the rate monotonic scheduler (RM).
- the deadline monotonic scheduler (DM).

RATE MONOTONIC SCHEDULER:
=========================

The rate monotonic scheduler sets the priority of the tasks acording to the period (P) of the tasks, so those tasks with a shorten period,
have a higher priority.

P - Periods
e - execution time
D - relative deadline

|          |   P     |    e    |   D     |  
------------------------------------------
|   T1     |   4     |    1    |   4     |        
------------------------------------------
|   T2     |   5     |    2    |   3     |        
------------------------------------------
|   T3     |   20    |    5    |   20    |        
------------------------------------------

In the table, T1, would get the highest priority, because his period is the shortest (P=4)

DEADLINE MONOTONIC SCHEDULER:
============================

In the deadline monotonic scheduler, the task with the smaller realtive deadline has the highest priority, in the tabl, that would
be T2, because its realtive deadline is the smallest (D=3).

NOTE:
> In case no deadline is set for a task, the DM algorithm is the same as the RM algorithm, because the period is the implicit deadline
> if nothing else is said.


EXAMPLE RM SCHEDULING:
=====================

We have the following preemptive system:

P - Periods
e - execution time
D - relative deadline


|          |   P     |    e    |   D     |  
------------------------------------------
|   T1     |   4     |    1    |   4     |        
------------------------------------------
|   T2     |   5     |    2    |   5     |        
------------------------------------------
|   T3     |   20    |    5    |   20    |        
------------------------------------------

Note that all the deadlines are identical to periods.

We want to schedule the tasks in the period [0,20]. Can we assure that all the tasks will meet the deadline?

First we look and the table, and check which task have the highest priority.- It's Task1, due it have the shortest period (P=4), it
has the highest priority. As T1, has the highest priority, it will be executed inmediatly when it's released.

 _____                   _____                   _____                   _____                   _____                                                
|     |                 |     |                 |     |                 |     |                 |     |          
|  T1 |                 | T1  |                 | T1  |                 | T1  |                 | T1  |           
|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|----->
0     1     2     3     4     5     6     7     8     9     10    11    12    13    14    15   16     17    18    19    20       time


The following task in priority is T2, because it has the second shortest period (P=5). So we allocate all the T2 Jobs, but they have
to respect the T1 task scheduling:


 _____ ___________       _____ ___________       _____       ___________ _____             _____ _____ _____                                             
|     |           |     |     |           |     |     |     |           |     |           |     |     |     |
|  T1 |     T2    |     | T1  |    T2     |     | T1  |     |     T2    | T1  |           |  T2 | T1  | T2  |
|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|----->
0     1     2     3     4     5     6     7     8     9     10    11    12    13    14    15   16     17    18    19    20       time


Finally Task T3 has the lowest priority, so Jobs of task3, have to be schedule only where there are space left in the timeline.


 _____ ___________ ____  _____ ___________ ____  _____ ____  ___________ _____ ___________ _____ _____ _____                                             
|     |           |     |     |           |     |     |     |           |     |           |     |     |     |
|  T1 |     T2    | T3  | T1  |    T2     |  T3 | T1  | T3  |     T2    | T1  |    T3     |  T2 | T1  | T2  |
|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|----->
0     1     2     3     4     5     6     7     8     9     10    11    12    13    14    15   16     17    18    19    20       time

And in this case we obtain a feaseble schedule, because no task ever miss its deadline.

EXAMPLE DM SCHEDULING:
=====================

Consider the following setup, in a preemptive system:

P - Periods
e - execution time
D - relative deadline


|          |   phase  |   P     |    e     |   D    |  
----------------------------------------------------
|   T1     |    50    |   50    |    25    |  100   |        
----------------------------------------------------
|   T2     |    0     |   62.5  |    10    |   20   |        
----------------------------------------------------
|   T3     |    0     |   125   |    25    |   50   |        
----------------------------------------------------

We want to schedule the tasks in the interval [0,250], and also want to know if the tasks will meet the deadline.

T1, has phase of 50, so that means that the first Job in T1, it will be shifted 50 ms.

Which is the task with the highest priority? It's T2, because is the task with the closest deadline. Therefore, the jobs, from T2,
will freely allocate.


 T           T           T           T           T 
 2           2           2           2           2
|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|----->
0           62.5        125         187.5       250              time(ms)

The task with the second highest priority, is task T3, because its relative deadline is 50, which is the second lowest deadline, thus
the second one in priority.

 T T T      T           T T T        T           T 
 2 3 3      2           2 3 3        2           2
|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|----->
0           62.5        125         187.5       250              time(ms)

Finally comes T1, which has the lowest priority because it has the latest deadline.

 T  T     T  T T     T T T T T    T T T T T      T 
 2  3     1  2 1     1 1 2 3 3    1 1 2 1 1      2
|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|----->
0           62.5        125         187.5       250              time(ms)

As we see, all the tasks, are done before the deadlines. :v:

COMPARATION BETWEEN DM AND RM:
=============================




VERIFIEN MONOTONIC SCHEDULERS:
=============================

We must assume that the number of tasks is constant, that jobs are independent, periodic and preemptable and all the jobs are 
schedulable at their release time.

The feasability of a schedule can be exhaustivily proven by simulating a timeline of: 2H + max{Pi} + max{Di}. We must simulate
two hyper-periods (H) because the system can be feaseble in the first hyper-period, but if the deadline of the last task is
inside the second hyper-period, this must be also taken into account.

RM test
=======

RM test can verify and guarantee timeline with the previous stated assumptions of the tasks. We define a limit called URM, as
the utilization limit under which the system is guaranteed to be feaseble. The feaseability can be proven by comparing the total
utilization U to the URM function. An the system is guaranteed to be feaseble if:

U =< URM(n) =< n*(2^(1/n) - 1) //n: number of tasks

Consider the following task set:

P - Periods
e - execution time
D - relative deadline

|          |   P     |    e     |   D     |  
------------------------------------------
|   T1     |   5     |    1     |   5     |        
------------------------------------------
|   T2     |   4     |    0.5   |   4     |        
------------------------------------------
|   T3     |   6     |    1.2   |   6     |        
------------------------------------------

So the total utilization of the system (U) is:

U = 1 / 5 + 0.5 / 4 + 1.2 / 6 = 0.525

URM(3) = 3 * (2^(1/3) -1) = 0.779

As U < URM, thus the system is guaranteed to be feaseble.

Consider now, the following tasks set:

P - Periods
e - execution time
D - relative deadline

|          |   P     |    e     |   D     |  
------------------------------------------
|   T1     |   5     |    1.9   |   5     |        
------------------------------------------
|   T2     |   4     |    1.5   |   4     |        
------------------------------------------
|   T3     |   6     |    2.2   |   6     |        
------------------------------------------

U = 1.9 / 5 + 1.5 / 4 + 2.2 / 6 = 1.12

URM(3) = 3 * (2^(1/3) -1) = 0.779

Since U >= URM and 1, the system is not feaseble.


Last example, consider the following taks set:

P - Periods
e - execution time
D - relative deadline

|          |   P     |    e   |   D     |  
------------------------------------------
|   T1     |   4     |    1   |   4     |        
------------------------------------------
|   T2     |   6     |    1   |   6     |        
------------------------------------------
|   T3     |   2     |    1   |   2     |        
------------------------------------------

U = 1 / 4 + 1 / 6 + 1 / 2 = 0.917 

URM(3) = 3 * (2^(1/3) -1) = 0.779

Since U>= URM, but U =< 1, neither feaseability nor overloading can be guaranteed. We should apply more tests to verify the system.













Poor-mans profiler:
-------------------

Profile a program, means to measure its performance, that is to say, it time execution (mostly)

CPU time measurement:
---------------------

CPU Time, is the CPU used time relative to a process, that is the amount of time that a certain process is using, of the CPU;
take into account, that if several process, are running in parallel, each one will use the CPU certain amount of time, that
depends on the operating system process squeduler.

If you want to check the time it takes a function from begining to end; then you can use the following `stdlib` function:

With the header file **'times.h'** or **'sys/times.h'**, you can use the function **`'clock()'`**, this will return a struct with the 
number of ticks of the clock for the current proces: 'clock_t', it really is another name for a 'long integer'.
For using this function, you have to call it at the start of the period
that  you want to measure, and at the end of it; Then, substract the **'start'** and **'end'** clocks, and ,divide it by the number of 
clock ticks per second (defined in the macro: **`CLOCKS_PER_SEC`**, or the 'sysconf' **`_SC_CLK_TCK_`**), to get the processor time.

Example:

```C
#include <time.h> //needed for: CLOCKS_PER_SEC, clock().

printf("debug: init: CLOCKS_PER_SEC: %d\n", CLOCK_PER_SEC); //safety check

. . .

clock_t start_tick= (clock_t)(-1), end_tack=(clock_t)(-1); //tick(start) & tack(end) CPU-time-ticks.
double cpu_time_used = 0; //measured used time. (check accuracy for the system)

...

start_tick = clock();

... // process data or else...

end_tack = clock();

if( start_tick != (clock_t)(-1) || end_tack != (clock_t)(-1) )
{
   cpu_time_used = ((double)(end_tack-start_tick)/(double)CLOCKS_PER_SEC);
   printf("debug:function %s cpu_time: %d sec\n",__FUNCTION__, cpu_time_used);  //info we want.
}
else
{  printf("error: function %s; clock() function error: \ntick: %d\ntack: %d",__FUNCTION__, start_tick, end_tack);}

```

Watch out!: 

Take into account, that different computers, and operating systems have different resolutions, and different methods to 
track time.`'clock()'` doesn't usually have more than some ms accuracy depending on the system.

If the clock() cant give you a result or it is not available, it returns the value '(clock_t)(-1)'.

There is an old macro: `'int **CLK_TCK**'` - don't use it. Use a newer one.

You should check the value of the clock_per_second constant that you system defines... just in case.

Portability Note: The clock function described in CPU Time is specified by the ISO C standard. 
clock() is standard C; it works "everywhere". There are system-specific functions, such as getrusage() on Unix-like systems.

reference: </br>
https://www.gnu.org/software/libc/manual/html_node/Time-Basics.html#Time-Basics </br>
https://www.gnu.org/software/libc/manual/html_node/CPU-Time.html#CPU-Time </br>
http://stackoverflow.com/questions/5248915/execution-time-of-c-program </br>

time interval measurement:
-------------------------

With the header file **'sys/times.h'**, watch out: not **'time.h'!!**, if you want to measure some time interval, you can use the function:

>'clock_t **times(struct tms *buffer)**'

The times function stores the processor time information for the calling process in buffer. Remeber 'clock_t' are the clock ticks.

the tms struct, contains at least the following fields:

- **clock_t tms_utime** - This is the total processor time the calling process has used in executing the instructions of its program.

- **clock_t tms_stime** - This is the processor time the system has used on behalf of the calling process.

- **clock_t tms_cutime** -In other words, it represents the total processor time used in executing the instructions of all the terminated child processes of the
calling process, excluding child processes which have not yet been reported by `'wait'` or `'waitpid'`.

- **clock_t tms_cstime** - This is similar to tms_cutime, but represents the total processor time the system has used on behalf of all the terminated child processes of the calling process.
terminated child processes of the calling process, excluding child processes which have not yet been reported by wait or waitpid.

**Macros**: defined in the macros: **`CLOCKS_PER_SEC`**, or the 'sysconf' **`_SC_CLK_TCK_`**. There is an old macro: `'int **CLK_TCK**'` - don't use it. Use a newer one.

**Portability Note**: The clock function described in CPU Time is specified by the ISO C standard. The times function is a feature of POSIX.1.
On GNU systems, the CPU time is defined to be equivalent to the sum of the tms_utime and tms_stime fields returned by times.

references:
https://www.gnu.org/software/libc/manual/html_node/Time-Basics.html#Time-Basics </br>
https://www.gnu.org/software/libc/manual/html_node/Processor-Time.html#Processor-Time </br>

Supervision of programs in Linux:
---------------------------------

It is easy to use an 'watchdog' daemon. The term 'watchdog' is usually refered and used to a mechanism that reset/reboots the
process/program/system if it detects that someahow is not running correctly or have stall at some point. Its a safe measurement.


references:
https://linux.die.net/man/8/watchdog <br>
https://linux.die.net/man/8/wd_keepalive <br>
https://linux.die.net/man/8/checkquorum <br>
https://linux.die.net/man/8/wdmd <br>
https://linux.die.net/man/8/wdmd_selinux <br>


Other tools in linux:
--------------------

You can use the Cyclictest program, it is used to measure performance of a system. Reference: https://rt.wiki.kernel.org/index.php/Cyclictest
Also you can monitor system calls with the **ltrace** and **strace** commands.
Also, please, review the testing Real time best practices: http://elinux.org/Realtime_Testing_Best_Practices




INiT ScRiPT DEF:
----------------

printf("CLOCKS_PER_SEC: %d\n", CLOCK_PER_SEC); //safety check








TODO:

 [ ] https://www.gnu.org/software/libc/manual/html_node/Overview-of-Syslog.html#Overview-of-Syslog  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Sysconf-Definition.html#Sysconf-Definition  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Backtraces.html#Backtraces  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Consistency-Checking.html#Consistency-Checking  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Error-Messages.html#Error-Messages  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Null-Pointer-Constant.html#Null-Pointer-Constant  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/index.html#toc-The-Basic-Program_002fSystem-Interface  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/index.html#toc-Debugging-support  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Error-Recovery.html#Error-Recovery  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Memory_002dmapped-I_002fO.html#Memory_002dmapped-I_002fO  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Resource-Usage-And-Limitation.html#Resource-Usage-And-Limitation  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Realtime-Scheduling.html#Realtime-Scheduling  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Basic-Scheduling-Functions.html#Basic-Scheduling-Functions  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Traditional-Scheduling.html#Traditional-Scheduling  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Program-Basics.html#Program-Basics  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Environment-Variables.html#Environment-Variables  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Processes.html#Processes  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Backtraces.html#Backtraces  <br>
 [ ] http://www.list.org/mailman-member/node13.html  <br>
 [ ] https://www.gnu.org/software/libc/  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Processes.html#Processes  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Program-Arguments.html#Program-Arguments  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Argument-Syntax.html#Argument-Syntax  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Auxiliary-Vector.html#Auxiliary-Vector  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Environment-Variables.html#Environment-Variables  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Environment-Access.html#Environment-Access  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/Standard-Environment.html#Standard-Environment  <br>
 [ ] https://linux.die.net/man/8/wd_keepalive  <br>
 [ ] https://linux.die.net/man/8/checkquorum  <br>
 [ ] https://gcc.gnu.org/ml/gcc-help/2015-06/msg00071.html  <br>
 [ ] https://solarianprogrammer.com/2012/10/14/cpp-11-timing-code-performance/  <br>
 [ ] http://www.thegeekstuff.com/2012/08/gprof-tutorial  <br>
 [ ] https://rusty.ozlabs.org/?p=330  <br>
 [ ] http://www.drdobbs.com/embedded-systems/measuring-execution-time-and-real-time-p/193502123  <br>
 [ ] http://stackoverflow.com/questions/5248915/execution-time-of-c-program  <br>
 [ ] MinGW compiler. –/ decent libc library. /   Windows XP with cygwin gcc & Linux Ubuntu.  <br>
 [ ] http://stackoverflow.com/questions/22387586/measuring-execution-time-of-a-function-in-c  <br>
 [ ] http://courseweb.stthomas.edu/resmith/c/cisc130/c9sp/gcc-timing.html  <br>
 [ ] https://www.gnu.org/software/libc/  <br>
 [ ] https://gcc.gnu.org/onlinedocs/gcc-4.6.4/gcc/Optimize-Options.html#Optimize-Options  <br>
 [ ] https://paolozaino.wordpress.com/2015/06/13/c-code-snippet-to-measure-function-execution-time-for-both-linux-and-mac-os-x/  <br>
 [ ] http://stackoverflow.com/questions/5644730/c-measuring-computing-time  <br>
 [ ] http://stackoverflow.com/questions/5644730/c-measuring-computing-time  <br>
 [ ] http://stackoverflow.com/questions/68907/how-do-you-measure-the-time-a-function-takes-to-execute  <br>
 [ ] http://stackoverflow.com/questions/68907/how-do-you-measure-the-time-a-function-takes-to-execute  <br>
 [ ] https://www.gnu.org/software/libc/manual/html_node/CPU-Time.html  <br>
 [ ] http://pcc.ludd.ltu.se/internals/  <br>
 [ ] http://www.tldp.org/LDP/Bash-Beginners-Guide/Bash-Beginners-Guide.pdf  <br>
 [ ] http://www.tldp.org/LDP/tlk/tlk.html  <br>
 [ ] preguntar documentación del último kernel  <br>
 [ ] https://kukuruku.co/post/writing-a-file-system-in-linux-kernel/  <br>
 [ ] http://stackoverflow.com/questions/4714056/how-to-implement-a-very-simple-filesystem  <br>
 [ ] https://en.wikipedia.org/wiki/MINIX_file_system  <br>
 [ ] http://linuxseekernel.blogspot.com.es/2014/06/create-simple-file-system.html  <br>
 [ ] http://www.linuxjournal.com/article/4335?page=0,0  <br>
 [ ]  http://www.linuxjournal.com/article/4395?page=0,0  <br>
 [ ] http://unix.stackexchange.com/questions/67462/linux-kernel-is-not-finding-the-initrd-correctly  <br>
 [ ] http://tr.opensuse.org/MicroSUSE_System_Builder's_Guide  <br>
 [ ] https://github.com/libfuse/libfuse  <br>
 [ ] http://elm-chan.org/fsw/ff/00index_e.html  <br>
 [ ] http://www.minix3.org/theses/gerofi-minix-vfs.pdf  <br>
 [ ] https://msdn.microsoft.com/en-us/library/aa363858(v=vs.85).aspx  <br>
 [ ] https://cboard.cprogramming.com/linux-programming/122773-simple-file-system-c.html  <br>
 [ ] http://www.flipcode.com/archives/Programming_a_Virtual_File_System-Part_I.shtml  <br>
 [ ] http://www.flipcode.com/archives/articles.shtml  <br>
 [ ] http://www.boost.org/doc/libs/1_57_0/libs/filesystem/doc/tutorial.html  <br>
 [ ] http://www.nobius.org/~dbg/practical-file-system-design.pdf  <br>
 [ ] https://developer.apple.com/library/content/documentation/FileManagement/Conceptual/FileSystemProgrammingGuide/Introduction/Introduction.html  <br>
 [ ] https://www.le.ac.uk/users/rjm1/cotter/page_77.htm  <br>
 [ ] http://www.geocities.ws/ravikiran_uvs/articles/rkfs-old.html  <br>
 [ ] https://www.codeproject.com/Tips/1005166/A-Simple-File-System  <br>
 [ ] https://www.quora.com/How-do-I-implement-a-basic-file-system-implementation-in-C-programming-using-inodes  <br>
 [ ] https://psankar.blogspot.com.es/2013/08/introducing-simplefs-ridiculously.html  <br>
 [ ] https://cboard.cprogramming.com/c-programming/95819-file-system-implementation.html  <br>
 [ ] https://en.wikipedia.org/wiki/Unix_File_System  <br>
 [ ] http://www.cs.cornell.edu/courses/cs4410/2010fa/CS4411/slides/project6/project6.pdf  <br>
 [ ] http://www.geocities.ws/ravikiran_uvs/articles/rkfs-old.html  <br>
 [ ] http://haifux.org/lectures/120/writing-linux-2.4-fs/writing-linux-2.4-fs.html  <br>
 [ ] https://github.com/psankar/simplefs  <br>
 [ ] http://www.cs.ucsb.edu/~chris/teaching/cs170/projects/proj5.html  <br>
 [ ] http://web.mit.edu/6.033/1997/handouts/html/04sfs.html  <br>
 [ ] http://pages.cs.wisc.edu/~remzi/OSTEP/file-implementation.pdf  <br>
 [ ] http://www.tldp.org/pub/Linux/docs/ldp-archived/linuxfocus/Castellano/September2001/article198.shtml <br>
 [ ] https://rt.wiki.kernel.org/index.php/Cyclictest <br>
 [ ] Real-Time Linux Wiki: https://rt.wiki.kernel.org/index.php/Main_Page
 [ ] comment on linux panic!!
 
